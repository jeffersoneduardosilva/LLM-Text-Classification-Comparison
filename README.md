# ü§ñ Compara√ß√£o de T√©cnicas de Classifica√ß√£o de Texto em LLMs: Zero-Shot, Fine-Tuning e RAG

Este projeto implementa e compara tr√™s estrat√©gias de Modelos de Linguagem (LLMs) para a tarefa de **Classifica√ß√£o de Texto Zero-Shot** em um dom√≠nio t√©cnico e academicamente denso: artigos cient√≠ficos do arXiv.

O principal objetivo √© avaliar o **trade-off entre o custo de treinamento/adapta√ß√£o e o desempenho** de cada abordagem na distin√ß√£o entre t√≥picos altamente correlacionados, como **Intelig√™ncia Artificial (AI)** e **Aprendizado de M√°quina (ML)**, utilizando as categorias `cs.AI` e `cs.LG`.

---

## üîó URL do Youtube / Apresenta√ß√£o do Projeto

| Tipo de Conte√∫do | Status | Link |
| :--- | :--- | :--- |
| **Apresenta√ß√£o do Projeto** | *Pendente* | [INSERIR_LINK_AQUI] |

---

## üöÄ Implementa√ß√£o e Estrat√©gias

O experimento utiliza um dataset balanceado de 1000 resumos de artigos cient√≠ficos (500 de `cs.AI` e 500 de `cs.LG`) coletados via API do arXiv.

### 1. Zero-Shot Classification (Modelo Base: BART-MNLI)

Esta abordagem serve como linha de base.

* **Modelo Utilizado:** `facebook/bart-large-mnli`. Este modelo √© treinado para a tarefa de *Infer√™ncia de Linguagem Natural* (NLI) no corpus MNLI e transfere essa capacidade para classifica√ß√£o, inferindo a rela√ß√£o entre o texto de entrada e o r√≥tulo candidato.
* **Mecanismo:** O classificador avalia qu√£o bem o resumo do artigo (`TEXTO ALVO`) implica ou contradiz o r√≥tulo (`AI` ou `ML`), sem a necessidade de qualquer dado rotulado de treino espec√≠fico do dom√≠nio.
* **Resultado do Notebook:** Apresentou a acur√°cia mais baixa ($\approx 49.5\%$), indicando que o modelo NLI pr√©-treinado tem dificuldade em diferenciar subdom√≠nios t√©cnicos com vocabul√°rio muito sobreposto.

### 2. Fine-Tuning (Adapta√ß√£o Supervisionada: SciBERT)

Esta √© a abordagem supervisionada padr√£o, que estabelece o teto de desempenho (benchmarking).

* **Modelo Utilizado:** `allenai/scibert_scivocab_uncased`. Foi escolhido por ser um modelo BERT otimizado e pr√©-treinado especificamente em uma grande cole√ß√£o de artigos cient√≠ficos, garantindo que o vocabul√°rio t√©cnico seja compreendido de forma mais eficaz.
* **Mecanismo:** O modelo √© ajustado (fine-tuned) por 3 √©pocas em 800 exemplos rotulados, aprendendo a mapear as caracter√≠sticas de texto para as classes `AI` (0) e `ML` (1).
* **Resultado do Notebook:** Alcan√ßou o melhor desempenho ($\approx 62.0\%$ de acur√°cia), o que era esperado devido ao ajuste direto √† tarefa e √† especializa√ß√£o do modelo base (SciBERT) no dom√≠nio cient√≠fico.

### 3. RAG - Retrieval-Augmented Classification (H√≠brido)

Esta abordagem busca melhorar a classifica√ß√£o Zero-Shot, adicionando contexto sem a necessidade de Fine-Tuning supervisionado.

* **Componentes:**
    1.  **Embeddings:** `all-mpnet-base-v2` (Sentence-Transformers) para codificar o corpus.
    2.  **√çndice Vetorial:** **FAISS** (`IndexFlatL2`) para busca r√°pida de vizinhos.
    3.  **Classificador:** O mesmo Zero-Shot **BART-MNLI**.
* **Mecanismo:**
    1.  Para cada texto de teste, os **K=5** artigos mais semanticamente similares s√£o recuperados do corpus indexado.
    2.  O texto original √© enriquecido com o t√≠tulo, resumo parcial e o r√≥tulo dos vizinhos mais pr√≥ximos.
    3.  Essa *entrada aumentada* √© fornecida ao classificador BART-MNLI para que ele use as informa√ß√µes de contexto (que j√° cont√™m o r√≥tulo verdadeiro de artigos similares) na sua decis√£o.
* **Resultado do Notebook:** Obteve desempenho intermedi√°rio ($\approx 57.5\%$ de acur√°cia), demonstrando que a **recupera√ß√£o sem√¢ntica √© eficaz** para aumentar a precis√£o da classifica√ß√£o Zero-Shot em dom√≠nios correlacionados.

---

## üìä Resumo Comparativo das M√©tricas

O `F1 Macro Score` √© a m√©trica principal, pois considera a precis√£o e o recall para ambas as classes (`AI` e `ML`), sendo mais robusta para avalia√ß√£o.

| M√©todo | Accuracy | F1 Macro Score |
| :--- | :--- | :--- |
| **Fine-Tuning (SciBERT)** | **0.6200** | **0.6153** |
| **RAG (Embeddings + Zero-Shot)** | 0.5750 | 0.5631 |
| **Zero-Shot (BART-MNLI)** | 0.4950 | 0.4826 |

---

## ‚öôÔ∏è Detalhes de Implementa√ß√£o

### Dataset e Pr√©-processamento

* **Fonte:** API do arXiv, categorias `cs.AI` e `cs.LG`.
* **Tamanho Total:** 1000 artigos (500 AI, 500 ML).
* **Divis√£o:** 800 para treino/corpus, 200 para teste.
* **Entrada do Modelo:** T√≠tulo e Abstract concatenados (`title + " - " + abstract`).

### Depend√™ncias (Instala√ß√£o)

```bash
# Necess√°rio rodar no notebook, idealmente em ambiente com GPU (para Fine-Tuning)
!pip install transformers datasets sentence-transformers faiss-cpu arxiv accelerate scikit-learn -q
!pip install --upgrade transformers accelerate datasets -q

üõ†Ô∏è Como Rodar o Notebook
O arquivo Trabalho_Final_Prof_Rogerio.ipynb cont√©m a implementa√ß√£o e a compara√ß√£o de tr√™s m√©todos de classifica√ß√£o de texto em LLMs (Zero-Shot, Fine-Tuning e RAG).

NOTA: Para garantir a execu√ß√£o bem-sucedida da etapa de Fine-Tuning e dos componentes de embeddings (RAG), √© altamente recomend√°vel usar um ambiente com GPU (Google Colab ou uma m√°quina local com setup CUDA) para reduzir drasticamente o tempo de processamento.

üíª Op√ß√£o 1: Rodar Localmente via VS Code
Esta op√ß√£o √© ideal se voc√™ possui um ambiente Python configurado e, preferencialmente, acesso a uma GPU local.

Pr√©-requisitos
Python: Tenha o Python (3.8+) instalado.

VS Code: Tenha o Visual Studio Code instalado.

Extens√µes do VS Code: Instale as seguintes extens√µes:

Jupyter

Python

Passos de Execu√ß√£o
Configurar Ambiente Virtual (Recomendado):

Bash

python -m venv venv
# Ativar no macOS/Linux:
source venv/bin/activate
# Ativar no Windows:
.\venv\Scripts\activate
Abrir e Conectar o Kernel:

Abra o arquivo Trabalho_Final_Prof_Rogerio.ipynb no VS Code.

Clique em "Select Kernel" (Canto superior direito) e escolha o ambiente virtual que voc√™ acabou de criar/ativar.

Instalar as Depend√™ncias:

Execute a primeira c√©lula do notebook (Se√ß√£o 0 - INSTALA√á√ïES INICIAIS) para garantir que todas as bibliotecas necess√°rias estejam instaladas no ambiente.

Executar o Projeto:

Execute as c√©lulas restantes em ordem sequencial (Se√ß√µes 1 a 13) para:

Importar bibliotecas.

Baixar os artigos do arXiv.

Realizar as tr√™s abordagens de classifica√ß√£o (Zero-Shot, Fine-Tuning e RAG).

Exibir o relat√≥rio de conclus√£o.

‚òÅÔ∏è Op√ß√£o 2: Rodar na Nuvem via Google Colab (Recomendado)
Esta √© a op√ß√£o mais simples e garante acesso a recursos de GPU para otimizar o tempo de execu√ß√£o.

Passos de Execu√ß√£o
Acessar o Colab: Abra o Google Colab (https://colab.research.google.com/).

Fazer Upload do Notebook:

Clique em "File" (Arquivo) > "Upload notebook" (Fazer upload de notebook).

Selecione e carregue o arquivo Trabalho_Final_Prof_Rogerio.ipynb.

Ativar a GPU (Passo Obrigat√≥rio para Fine-Tuning):

V√° em "Runtime" (Ambiente de execu√ß√£o) no menu superior.

Selecione "Change runtime type" (Alterar tipo de ambiente de execu√ß√£o).

Em "Hardware accelerator", escolha GPU.

Clique em "Save" (Salvar).

Executar Todas as C√©lulas:

V√° em "Runtime" (Ambiente de execu√ß√£o) no menu superior.

Selecione "Run all" (Executar tudo).

O Colab ir√° instalar as depend√™ncias, baixar os dados do arXiv e executar todas as etapas da compara√ß√£o de modelos. O processo de Fine-Tuning (Se√ß√£o 8) ser√° o mais demorado, mesmo com a GPU ativa.
